# src/main.py
import os
import json
import time
import logging
import schedule
from datetime import datetime, timedelta

# ä¿®æ”¹å¯¼å…¥æ–¹å¼ä»¥åŒ¹é…ç°æœ‰ç»“æ„
from modules.market_data import MarketData
from modules.nlp_analyzer import NLPAnalyzer
from modules.twitter_client import TwitterClient
from modules.technical_analysis import TechnicalAnalysis
from modules.chart_generator import ChartGenerator

# å¯¼å…¥æ–°æ¨¡å—
from modules.social_data_collector import SocialDataCollector
from modules.user_interaction import UserInteractionHandler
from modules.content_generator import ContentGenerator

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("logs/bot.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
os.makedirs('data/charts', exist_ok=True)
os.makedirs('data/signals', exist_ok=True)
os.makedirs('data/social', exist_ok=True)
os.makedirs('logs', exist_ok=True)

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    logger.info("Starting Cryptocurrency Analysis Bot...")
    
    # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
    twitter_client = TwitterClient()
    nlp_analyzer = NLPAnalyzer()
    tech_analyzer = TechnicalAnalysis()
    chart_gen = ChartGenerator()
    market_data_client = MarketData()  # ä½¿ç”¨æ‚¨çš„MarketDataç±»
    
    # åˆå§‹åŒ–æ–°æ¨¡å—
    social_collector = SocialDataCollector(twitter_client)
    user_handler = UserInteractionHandler(twitter_client, nlp_analyzer, market_data_client)
    content_generator = ContentGenerator(openai_client=None, nlp_analyzer=nlp_analyzer)
    
    # å®šä¹‰ä»»åŠ¡
    def collect_expanded_data():
        """æ”¶é›†æ‰©å±•çš„å¸‚åœºå’Œç¤¾äº¤æ•°æ®"""
        logger.info("Collecting expanded social and market data...")
        timestamp = datetime.now().strftime('%Y%m%d_%H%M')
        
        # æ”¶é›†å¸‚åœºæ•°æ® - ä½¿ç”¨MarketDataç±»çš„æ–¹æ³•
        try:
            # è·å–é¡¶çº§åŠ å¯†è´§å¸æ•°æ®
            top_coins_df = market_data_client.get_top_coins(limit=100)
            
            # è®¡ç®—å¸‚åœºæŒ‡æ ‡
            market_indicators = market_data_client.calculate_market_indicators(top_coins_df)
            
            # è·å–è¶‹åŠ¿å¸ç§
            trending_coins = market_data_client.get_trending_coins()
            
            # æ„å»ºå®Œæ•´çš„å¸‚åœºæ•°æ®å¯¹è±¡
            market_data_result = {
                'btc_price': float(top_coins_df[top_coins_df['id'] == 'bitcoin']['current_price'].values[0]) if 'bitcoin' in top_coins_df['id'].values else 65000,
                'eth_price': float(top_coins_df[top_coins_df['id'] == 'ethereum']['current_price'].values[0]) if 'ethereum' in top_coins_df['id'].values else 3500,
                'total_market_cap': market_indicators.get('total_market_cap', '$2.5T'),
                'btc_dominance': market_indicators.get('bitcoin_dominance', 48),
                'total_volume_24h': top_coins_df['total_volume'].sum() if not top_coins_df.empty else 100000000000,
                'market_indicators': market_indicators,
                'top_coins': top_coins_df.head(20).to_dict('records') if not top_coins_df.empty else [],
                'trending_coins': trending_coins,
                'timestamp': datetime.now().isoformat()
            }
            
            # æ·»åŠ äº¤æ˜“ä¿¡å·å’Œå¼‚å¸¸
            market_data_result['signals'] = {}
            market_data_result['anomalies'] = []
            
            # æå–é¡¶çº§èµ¢å®¶å’Œè¾“å®¶ä½œä¸ºè¶‹åŠ¿å’Œå¼‚å¸¸
            if 'top_gainers' in market_indicators and market_indicators['top_gainers']:
                for gainer in market_indicators['top_gainers'][:2]:
                    market_data_result['signals'][gainer['symbol'].upper()] = {
                        'direction': 'buy',
                        'strength': min(abs(gainer['price_change_percentage_24h']) / 10, 1.0),
                        'timestamp': datetime.now().isoformat()
                    }
            
            if 'top_losers' in market_indicators and market_indicators['top_losers']:
                for loser in market_indicators['top_losers'][:2]:
                    # è¶…è¿‡10%çš„æŸå¤±æ·»åŠ ä¸ºå¼‚å¸¸
                    if abs(loser['price_change_percentage_24h']) > 10:
                        market_data_result['anomalies'].append({
                            'asset': loser['symbol'].upper(),
                            'description': f"abnormal drop of {abs(loser['price_change_percentage_24h']):.1f}%",
                            'confidence': min(abs(loser['price_change_percentage_24h']) * 2, 90),
                            'timestamp': datetime.now().isoformat()
                        })
                    # å¦åˆ™æ·»åŠ ä¸ºå–å‡ºä¿¡å·
                    else:
                        market_data_result['signals'][loser['symbol'].upper()] = {
                            'direction': 'sell',
                            'strength': min(abs(loser['price_change_percentage_24h']) / 10, 1.0),
                            'timestamp': datetime.now().isoformat()
                        }
        except Exception as e:
            logger.error(f"Error collecting market data: {str(e)}")
            market_data_result = {
                'btc_price': 65000,
                'eth_price': 3500,
                'timestamp': datetime.now().isoformat()
            }
        
        with open(f"data/market_data_{timestamp}.json", 'w') as f:
            json.dump(market_data_result, f)
        logger.info(f"Market data collected and saved to data/market_data_{timestamp}.json")
        
        # æ”¶é›†ç¤¾äº¤æ•°æ®
        reddit_data = nlp_analyzer.fetch_reddit_sentiment()
        kol_tweets = social_collector.collect_kol_tweets(hours=6)  # è·å–æœ€è¿‘6å°æ—¶çš„KOLæ¨æ–‡
        community_tweets = social_collector.collect_community_sentiment()
        
        # åˆå¹¶æ‰€æœ‰ç¤¾äº¤æ•°æ®
        all_social_data = {
            'reddit': reddit_data,
            'kol_tweets': kol_tweets,
            'community': community_tweets
        }
        
        # åˆ†æç¤¾äº¤æ•°æ®
        try:
            if hasattr(nlp_analyzer, 'analyze_alternative_sources'):
                social_analysis = nlp_analyzer.analyze_alternative_sources()
            else:
                # ä½¿ç”¨é»˜è®¤çš„ç¤¾äº¤åˆ†ææ–¹æ³•
                social_analysis = {'sentiment': 0.2, 'topics': [('bitcoin', 5), ('ethereum', 4), ('defi', 3)]}
                
                # å‡†å¤‡è¶‹åŠ¿å¸ç§
                trending_tokens = []
                if trending_coins:
                    trending_tokens = [coin['symbol'].upper() for coin in trending_coins[:5]]
                
                # æ·»åŠ åˆ°ç¤¾äº¤åˆ†æç»“æœ
                social_analysis['mentioned_tokens'] = trending_tokens
        except Exception as e:
            logger.error(f"Error analyzing social data: {str(e)}")
            social_analysis = {'sentiment': 'neutral'}
        
        # ä¿å­˜ç¤¾äº¤æ•°æ®å’Œåˆ†æç»“æœ
        social_data_file = f"data/social_data_{timestamp}.json"
        with open(social_data_file, 'w') as f:
            json.dump({
                'data': all_social_data,
                'analysis': social_analysis
            }, f)
        logger.info(f"Social data collected and saved to {social_data_file}")
        
        return market_data_result, social_analysis
    
    def generate_and_post_market_update():
        """ç”Ÿæˆå¹¶å‘å¸ƒå¸‚åœºæ›´æ–°"""
        logger.info("Generating market updates...")
        timestamp = datetime.now().strftime('%Y%m%d_%H%M')
        
        # æ”¶é›†æ•°æ®
        market_data_result, social_analysis = collect_expanded_data()
        
        # ç”Ÿæˆå¸‚åœºæ¦‚è§ˆå›¾è¡¨
        chart_path = f"data/charts/market_overview_{timestamp}.png"
        try:
            # å°è¯•ä½¿ç”¨chart_genå¯¹è±¡
            chart_gen.generate_market_overview(market_data_result, output_path=chart_path)
            logger.info(f"Market overview chart saved to {chart_path}")
        except Exception as e:
            logger.error(f"Error generating market overview chart: {str(e)}")
            chart_path = None
        
        # ç”ŸæˆæŠ€æœ¯åˆ†æå›¾è¡¨
        chart_paths = {}
        for symbol in ['BTC', 'ETH', 'BNB', 'SOL', 'XRP']:
            ta_chart_path = f"data/charts/{symbol}_analysis_{timestamp}.png"
            try:
                chart_gen.generate_technical_chart(symbol, output_path=ta_chart_path)
                chart_paths[symbol] = ta_chart_path
                logger.info(f"{symbol} technical analysis chart saved to {ta_chart_path}")
            except Exception as e:
                logger.error(f"Error generating {symbol} technical chart: {str(e)}")
        
        # ç”Ÿæˆå¸‚åœºåˆ†ææ–‡æœ¬
        market_update = content_generator.generate_market_update(market_data_result, social_analysis)
        trend_analysis = content_generator.generate_trend_analysis(market_data_result, social_analysis)
        
        # ä¿å­˜åˆ†æåˆ°æ–‡ä»¶
        analysis_file = f"data/analysis_{timestamp}.txt"
        with open(analysis_file, 'w') as f:
            f.write(f"{market_update}\n\n{trend_analysis}")
        logger.info(f"Market analysis saved to {analysis_file}")
        
        # å‘å¸ƒåˆ°Twitter
        logger.info("Posting market analysis to Twitter...")
        
        # å‘å¸ƒå¸‚åœºæ›´æ–°
        tweet_id = None
        if chart_path and os.path.exists(chart_path):
            tweet_id = twitter_client.post_tweet_with_media(
                text=market_update,
                media_path=chart_path
            )
        else:
            # å¦‚æœæ²¡æœ‰å›¾è¡¨ï¼Œåªå‘å¸ƒæ–‡æœ¬
            tweet_id = twitter_client.post_tweet(market_update)
        
        # å¦‚æœæœ‰è¶‹åŠ¿åˆ†æï¼Œä½œä¸ºå›å¤å‘å¸ƒ
        if trend_analysis and tweet_id:
            twitter_client.reply_to_tweet(
                tweet_id=tweet_id,
                text=trend_analysis
            )
            logger.info("Analysis thread successfully posted to Twitter")
            
        # å‘å¸ƒäº¤æ˜“ä¿¡å·
        if 'signals' in market_data_result and market_data_result['signals']:
            signals_text = "ğŸ“ˆ #TradingSignal Alert:\n"
            for symbol, signal in list(market_data_result['signals'].items())[:3]:  # é™åˆ¶ä¸ºå‰3ä¸ªä¿¡å·
                direction = "ğŸŸ¢ BUY" if signal.get('direction') == 'buy' else "ğŸ”´ SELL"
                strength = signal.get('strength', 0.5)
                signals_text += f"{direction} {symbol}: Strength {strength:.1f}/1.0\n"
                
            twitter_client.post_tweet(signals_text)
            logger.info("Trading signals posted to Twitter")
            
        # å‘å¸ƒå¼‚å¸¸è­¦æŠ¥
        if 'anomalies' in market_data_result and market_data_result['anomalies']:
            anomaly_text = "ğŸš¨ #MarketAnomaly Alert:\n"
            for anomaly in market_data_result['anomalies'][:2]:  # é™åˆ¶ä¸ºå‰2ä¸ªå¼‚å¸¸
                asset = anomaly.get('asset', 'Unknown')
                description = anomaly.get('description', 'unusual activity')
                confidence = anomaly.get('confidence', 50)
                anomaly_text += f"{asset}: {description} ({confidence:.1f}% confidence)\n"
                
            twitter_client.post_tweet(anomaly_text)
            logger.info("Anomaly alerts posted to Twitter")
            
        # å‘å¸ƒç®€å•çš„å¸‚åœºæ›´æ–°
        btc_price = market_data_result.get('btc_price', '?')
        market_cap = market_data_result.get('total_market_cap', '?')
        volume_24h = market_data_result.get('total_volume_24h', '?')
        btc_dominance = market_data_result.get('btc_dominance', '?')
        
        summary = f"ğŸ“Š #Crypto Market Update ({datetime.now().strftime('%Y-%m-%d %H:%M')}):\n"
        summary += f"BTC: ${btc_price}\n"
        summary += f"Total Market Cap: ${market_cap:,.0f}\n" if isinstance(market_cap, (int, float)) else f"Total Market Cap: {market_cap}\n"
        summary += f"24h Volume: ${volume_24h:,.0f}\n" if isinstance(volume_24h, (int, float)) else f"24h Volume: {volume_24h}\n"
        summary += f"BTC Dominance: {btc_dominance:.1f}%" if isinstance(btc_dominance, (int, float)) else f"BTC Dominance: {btc_dominance}"
        
        if chart_path and os.path.exists(chart_path):
            twitter_client.post_tweet_with_media(
                text=summary,
                media_path=chart_path
            )
        else:
            twitter_client.post_tweet(summary)
            
        logger.info("Simple market update posted to Twitter")
        logger.info("Market analysis successfully generated")
        
        return True
    
    def check_user_interactions():
        """æ£€æŸ¥ç”¨æˆ·äº’åŠ¨å¹¶å›å¤"""
        logger.info("Checking for user interactions...")
        user_handler.check_and_respond_mentions()
    
    # è®¾ç½®å®šæ—¶ä»»åŠ¡
    schedule.every(30).minutes.do(collect_expanded_data)
    schedule.every(1).hours.do(generate_and_post_market_update)
    schedule.every(5).minutes.do(check_user_interactions)
    
    # ä¸»å¾ªç¯
    logger.info("All tasks scheduled, starting main loop")
    
    # å¯åŠ¨æ—¶å…ˆè¿è¡Œä¸€æ¬¡æ•°æ®æ”¶é›†å’Œå¸‚åœºæ›´æ–°
    try:
        generate_and_post_market_update()
    except Exception as e:
        logger.error(f"Error during initial market update: {str(e)}")
    
    while True:
        try:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡å®šæ—¶ä»»åŠ¡
        except Exception as e:
            logger.error(f"Error in main loop: {str(e)}")
            time.sleep(300)  # å¦‚æœå‡ºé”™ï¼Œç­‰å¾…5åˆ†é’Ÿå†ç»§ç»­

if __name__ == "__main__":
    main()